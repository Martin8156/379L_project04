{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8565bff-79b3-4640-9454-8e8c7f793058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 15:12:33.532412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746457954.143980   29046 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746457954.357434   29046 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746457955.724370   29046 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746457955.724462   29046 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746457955.724464   29046 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746457955.724467   29046 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-05 15:12:35.853025: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline, DataCollatorWithPadding, AutoTokenizer, AutoModelForMaskedLM, TrainingArguments, Trainer\n",
    "from collections import Counter\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfc7a09-421f-45b8-a4a3-b98c9e306506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_ids', 'default_seq', 'correction_seq', 'diff_type'],\n",
       "        num_rows: 10769\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"community-datasets/youtube_caption_corrections\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ff1c72-c18e-4a3c-98ba-97805e15b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping function\n",
    "def find_punctuation_errors(dataset):\n",
    "    masked_default_seq_list = []\n",
    "    correct_punctuation = ''\n",
    "    first_mask_detected = 0\n",
    "    \n",
    "    for i, error_val in enumerate(dataset[\"diff_type\"]):\n",
    "        masked_default_seq_list.append(dataset['default_seq'][i])\n",
    "        if error_val == 2 and first_mask_detected:\n",
    "            break\n",
    "        elif error_val == 2:\n",
    "            first_mask_detected += 1\n",
    "            masked_default_seq_list.append(\"[MASK]\")  \n",
    "            # at this index, we want to extract the correct punctuation at the same index in correction_seq ()\n",
    "            # dataset has corrected punctuations stored in this format: \"[word][punctuation]\"\n",
    "            correct_punctuation = dataset[\"correction_seq\"][i][-1]\n",
    "\n",
    "    # handle case where no punctuation error was found\n",
    "    if correct_punctuation == '': \n",
    "        return None\n",
    "        \n",
    "    return {\n",
    "        \"masked_default_seq\": ' '.join(masked_default_seq_list),\n",
    "        \"punctuation\": correct_punctuation\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d39e18-5776-4c0b-b461-a8ce6754210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_ids', 'default_seq', 'correction_seq', 'diff_type'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = dataset['train'].select([0])\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f5cea7-54f0-4b8f-9e93-6062e632b567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_ids', 'default_seq', 'correction_seq', 'diff_type', 'masked_default_seq', 'punctuation'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply mapping on subset test to verify correctness\n",
    "modified_subset = subset.map(find_punctuation_errors)\n",
    "modified_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2dff941-f76b-4eaf-ab2e-bc647217cd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey everybody [MASK] ivan from weights and biases here'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_subset['masked_default_seq'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ca36c4-bac5-4aa1-af75-7d163952aa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_subset['punctuation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b82271c-19ab-4eb3-aa3f-7fb874f73339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_ids', 'default_seq', 'correction_seq', 'diff_type', 'masked_default_seq', 'punctuation'],\n",
       "    num_rows: 10747\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets apply masking to entire dataset to create the new 'masked_default_seq' column\n",
    "new_dataset = dataset.map(find_punctuation_errors)\n",
    "new_dataset = new_dataset['train']\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9792c6e-1893-4c71-b004-23a87bf6a113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_ids', 'default_seq', 'correction_seq', 'diff_type', 'masked_default_seq', 'punctuation'],\n",
       "    num_rows: 10648\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out None rows and Nonpunctuations\n",
    "acceptedPunctuationTypes = ['.', ',', ';', ':', '-', '?', '!']\n",
    "cleaned_dataset = new_dataset.filter(lambda x: x['masked_default_seq'] is not None and x['punctuation'] in acceptedPunctuationTypes)\n",
    "cleaned_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a187f403-f55a-4b04-9bb6-0279728fb919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_ids', 'default_seq', 'correction_seq', 'diff_type', 'masked_default_seq', 'punctuation'],\n",
       "        num_rows: 8518\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_ids', 'default_seq', 'correction_seq', 'diff_type', 'masked_default_seq', 'punctuation'],\n",
       "        num_rows: 2130\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train, test, and validation\n",
    "cleaned_dataset = cleaned_dataset.train_test_split(test_size=0.2, seed=1227)\n",
    "cleaned_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ccf825-cdcb-446d-ab8f-46e41d327be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment Section 1 if CPU/GPU Usage is not a problem, then uncomment the subsequent sections involving 'validationSet'\n",
    "\n",
    "# 1)\n",
    "train_validation_dataset = cleaned_dataset['train'].train_test_split(test_size= 0.25, seed=1227)\n",
    "testSet = cleaned_dataset['test']\n",
    "trainSet = train_validation_dataset['train']\n",
    "validationSet = train_validation_dataset['test']\n",
    "\n",
    "# 2)\n",
    "# testSet = cleaned_dataset['test']\n",
    "# trainSet = cleaned_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a889fc8e-50b3-4b97-91c6-cbb27d7434d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({',': 3079, '.': 3017, '?': 168, '-': 66, ':': 41, ';': 11, '!': 6})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(trainSet['punctuation'])\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4129cc51-f451-4541-b64c-7dce9bc8a244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you might recognize what we have here in yellow as the general form of a p-series and what we're going to do in this video is think about under which conditions under for what Peas will this pea series converge and for it to be a p-series by definition P is going to be greater than zero [MASK] so I've set up some visualizations to think about how we are going to understand when this pea series converges so over here you have the graph\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_example = trainSet['masked_default_seq'][0]\n",
    "train_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c66a696f-d1a3-4133-af08-f0a5df6c730e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet['punctuation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f845cb5c-7d94-498f-a8f9-e78fb0b19528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.34914007782936096,\n",
       "  'token': 1010,\n",
       "  'token_str': ',',\n",
       "  'sequence': \"you might recognize what we have here in yellow as the general form of a p - series and what we ' re going to do in this video is think about under which conditions under for what peas will this pea series converge and for it to be a p - series by definition p is going to be greater than zero, so i ' ve set up some visualizations to think about how we are going to understand when this pea series converges so over here you have the graph\"},\n",
       " {'score': 0.3287944495677948,\n",
       "  'token': 1012,\n",
       "  'token_str': '.',\n",
       "  'sequence': \"you might recognize what we have here in yellow as the general form of a p - series and what we ' re going to do in this video is think about under which conditions under for what peas will this pea series converge and for it to be a p - series by definition p is going to be greater than zero. so i ' ve set up some visualizations to think about how we are going to understand when this pea series converges so over here you have the graph\"},\n",
       " {'score': 0.17926400899887085,\n",
       "  'token': 1998,\n",
       "  'token_str': 'and',\n",
       "  'sequence': \"you might recognize what we have here in yellow as the general form of a p - series and what we ' re going to do in this video is think about under which conditions under for what peas will this pea series converge and for it to be a p - series by definition p is going to be greater than zero and so i ' ve set up some visualizations to think about how we are going to understand when this pea series converges so over here you have the graph\"},\n",
       " {'score': 0.014141339808702469,\n",
       "  'token': 2061,\n",
       "  'token_str': 'so',\n",
       "  'sequence': \"you might recognize what we have here in yellow as the general form of a p - series and what we ' re going to do in this video is think about under which conditions under for what peas will this pea series converge and for it to be a p - series by definition p is going to be greater than zero so so i ' ve set up some visualizations to think about how we are going to understand when this pea series converges so over here you have the graph\"},\n",
       " {'score': 0.012900725938379765,\n",
       "  'token': 2133,\n",
       "  'token_str': '...',\n",
       "  'sequence': \"you might recognize what we have here in yellow as the general form of a p - series and what we ' re going to do in this video is think about under which conditions under for what peas will this pea series converge and for it to be a p - series by definition p is going to be greater than zero... so i ' ve set up some visualizations to think about how we are going to understand when this pea series converges so over here you have the graph\"}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference model on basic example via a pipeline\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"google-bert/bert-base-uncased\")\n",
    "result = fill_mask(train_example)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8923896-558a-4e8c-a6d5-648224f5f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tokenizer, collator and metric for model testing\n",
    "checkpoint = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "metric = load('accuracy')\n",
    "def compute_metrics(preds):\n",
    "    logits, labels = preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    mask = labels != -100\n",
    "    return metric.compute(predictions=predictions[mask], references=labels[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d449b3c-721b-4526-8fae-5aed6e66c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize datasets to create ids of the input str list containing the [MASK] token\n",
    "# def preprocess(examples):\n",
    "#     model_inputs = tokenizer(examples[\"masked_default_seq\"], truncation=True, padding=True)\n",
    "#     labels = tokenizer(examples[\"punctuation\"], padding=True, truncation=True)\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"] # ground truth labels in id form\n",
    "#     return model_inputs\n",
    "\n",
    "# Compute loss at [MASK] position\n",
    "def preprocess(example):\n",
    "    tokens = tokenizer(example[\"masked_default_seq\"], padding=\"max_length\", truncation=True, max_length=128) # needed to specify padding to max_length, else unable to create tensors\n",
    "    labels = [-100] * len(tokens[\"input_ids\"])\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "    if mask_token_id in tokens[\"input_ids\"]:\n",
    "        mask_index = tokens[\"input_ids\"].index(mask_token_id)\n",
    "        label_token_id = tokenizer.convert_tokens_to_ids(example[\"punctuation\"])\n",
    "        labels[mask_index] = label_token_id\n",
    "    tokens[\"labels\"] = labels\n",
    "    return tokens\n",
    "\n",
    "trainSet_tokenized = trainSet.map(preprocess)\n",
    "validationSet_tokenized = validationSet.map(preprocess)\n",
    "testSet_tokenized = testSet.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb83322-cba8-4c9b-8171-1d4723006552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_ids', 'default_seq', 'correction_seq', 'diff_type', 'masked_default_seq', 'punctuation', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 6388\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c9c3e3e-059e-4e0a-bf6c-bc6dab9d5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused features\n",
    "unused_features = ['video_ids', 'default_seq', 'correction_seq', 'diff_type', 'masked_default_seq', 'punctuation', 'token_type_ids']\n",
    "trainSet_tokenized = trainSet_tokenized.remove_columns(unused_features)\n",
    "validationSet_tokenized = validationSet_tokenized.remove_columns(unused_features)\n",
    "testSet_tokenized = testSet_tokenized.remove_columns(unused_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16834a4e-fd8e-4abf-ac2f-a5c986cccf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 6388\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ba2ec20-6d2d-4f60-850c-f19fdcf1320f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_29046/3100713962.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Set up general training args\n",
    "batch_size = 16\n",
    "args = TrainingArguments(\n",
    "    f\"BERT-finetuned-punctuationAccuracy\", \n",
    "    eval_strategy = \"no\", # kernel kept dying so changed this from \"epoch\"\n",
    "    save_strategy = \"no\", # kernel kept dying so chnaged this from \"epoch\"\n",
    "    learning_rate=2e-5, \n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=1, # kernel kept dying so changed this from \"5\"\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Model Instantiation\n",
    "model = AutoModelForMaskedLM.from_pretrained(checkpoint) # model architecture for fill-mask operations\n",
    "trainer = Trainer(\n",
    "    model, \n",
    "    args,  \n",
    "    train_dataset=trainSet_tokenized, \n",
    "    #eval_dataset=validationSet_tokenized, # kernel kept dying so removed validation set entirely\n",
    "    tokenizer=tokenizer, # note: deprecated argument\n",
    "    data_collator=data_collator,  \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f33c4ae-37ac-4efb-9958-7190fbf91df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 22:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"finetuned-BERT-punctuation-restoration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c89b236-8119-4583-b1a9-002fee5e3a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 01:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.43367841839790344,\n",
       " 'eval_model_preparation_time': 0.0026,\n",
       " 'eval_accuracy': 0.8444444444444444,\n",
       " 'eval_runtime': 95.8793,\n",
       " 'eval_samples_per_second': 5.215,\n",
       " 'eval_steps_per_second': 0.657}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POST-TRAINING\n",
    "# Reloading trained model from local directory\n",
    "finetuned_model = AutoModelForMaskedLM.from_pretrained(\"finetuned-BERT-punctuation-restoration\")\n",
    "finetuned_trainer = Trainer(model=finetuned_model, compute_metrics=compute_metrics)\n",
    "results = finetuned_trainer.evaluate(eval_dataset=testSet_tokenized.select(range(500))) # kernel dies here, so operate on subset of test data\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e301aa2e-0f84-41fa-9a6c-0c2b64d98e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 01:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.4030957221984863,\n",
       " 'eval_model_preparation_time': 0.0026,\n",
       " 'eval_accuracy': 0.5838383838383838,\n",
       " 'eval_runtime': 88.5696,\n",
       " 'eval_samples_per_second': 5.645,\n",
       " 'eval_steps_per_second': 0.711}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with base model\n",
    "base = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
    "base_trainer = Trainer(model=base, compute_metrics=compute_metrics)\n",
    "base_results = base_trainer.evaluate(eval_dataset=testSet_tokenized.select(range(500)))\n",
    "base_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957de76e-5744-4a33-bafe-0af495ae0db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
